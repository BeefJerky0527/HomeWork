{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP+JRTYdtqjE5gFDfjK1LU4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeefJerky0527/HomeWork/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WACm5tTU-dIN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HW3_LJH(pycharm에서 실행)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tITnJDH49wTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 1. normal dual layer perception code\n",
        "\n",
        "!pip install -q tensorflow-gpu==2.0.0-rc1\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# read MNIST\n",
        "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
        "print('train dataset:',mnist.train.images.shape,mnist.train.labels.shape)\n",
        "print('test datset:',mnist.test.images.shape, mnist.train.labels.shape)\n",
        "print('validationi dataset:', mnist.validation.images.shape, mnist.validation.labels.shape)\n",
        "\n",
        "# placeholder to feed data to graph 28x28=784\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "# layer 1 processing\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L2, W3)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "# Data feed\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.InteractiveSession()\n",
        "# Pass image tensor object to a PIL image\n",
        "sess.run(init)\n",
        "\n",
        "# mini batch operation, batchsize=100\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "for epoch in range(20):\n",
        "    total_cost = 0\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.8})\n",
        "        total_cost += cost_val\n",
        "\n",
        "    print('Epoch: ', '%04d' % (epoch + 1),'Avg. Cost = ', '{:.3f}'.format(total_cost / total_batch))\n",
        "print('Optimized')\n",
        "\n",
        "# Verification\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('Accuracy: ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
        "labels = sess.run(model, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1})\n",
        "\n",
        "\n",
        "# figure\n",
        "fig = plt.figure()\n",
        "for i in range(10):\n",
        "    subplot = fig.add_subplot(2, 5, i+1)\n",
        "    subplot.set_xticks([])\n",
        "    subplot.set_yticks([])\n",
        "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
        "    subplot.imshow(mnist.test.images[i].reshape((28,28)), cmap=plt.gray())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUYB_GHgAqLS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "C:\\ProgramData\\Anaconda3\\envs\\LJH\\python.exe C:/Users/이종현/PycharmProjects/untitled3/data/MNIST7.py\n",
        "Extracting data/train-images-idx3-ubyte.gz\n",
        "Extracting data/train-labels-idx1-ubyte.gz\n",
        "Extracting data/t10k-images-idx3-ubyte.gz\n",
        "Extracting data/t10k-labels-idx1-ubyte.gz\n",
        "2020-06-02 21:42:06.355180: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
        "Epoch:  0001 Avg. Cost =  0.428\n",
        "Epoch:  0002 Avg. Cost =  0.165\n",
        "Epoch:  0003 Avg. Cost =  0.115\n",
        "Epoch:  0004 Avg. Cost =  0.090\n",
        "Epoch:  0005 Avg. Cost =  0.073\n",
        "Epoch:  0006 Avg. Cost =  0.061\n",
        "Epoch:  0007 Avg. Cost =  0.051\n",
        "Epoch:  0008 Avg. Cost =  0.045\n",
        "Epoch:  0009 Avg. Cost =  0.041\n",
        "Epoch:  0010 Avg. Cost =  0.038\n",
        "Optimized\n",
        "Accuracy:  0.9796"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m47AFlRhApJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 2.1 좌우로 Flipping 한 MNIST dual layer perception code\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# read MNIST\n",
        "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
        "print('train dataset:',mnist.train.images.shape,mnist.train.labels.shape)\n",
        "print('test datset:',mnist.test.images.shape, mnist.train.labels.shape)\n",
        "print('validationi dataset:', mnist.validation.images.shape, mnist.validation.labels.shape)\n",
        "\n",
        "# placeholder to feed data to graph 28x28=784\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "# layer 1 processing\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L2, W3)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "# Data feed\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.InteractiveSession()\n",
        "# Pass image tensor object to a PIL image\n",
        "sess.run(init)\n",
        "\n",
        "# mini batch operation, batchsize=100\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "for epoch in range(20):\n",
        "    total_cost = 0\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        # flipping left<->right\n",
        "        batch_xs = np.fliplr(batch_xs)\n",
        "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.8})\n",
        "        total_cost += cost_val\n",
        "\n",
        "    print('Epoch: ', '%04d' % (epoch + 1),'Avg. Cost = ', '{:.3f}'.format(total_cost / total_batch))\n",
        "print('Optimized')\n",
        "\n",
        "# Verification\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('Accuracy: ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
        "labels = sess.run(model, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1})\n",
        "\n",
        "\n",
        "# figure\n",
        "fig = plt.figure()\n",
        "for i in range(5):\n",
        "    subplot = fig.add_subplot(2, 5, i+1)\n",
        "    subplot.set_xticks([])\n",
        "    subplot.set_yticks([])\n",
        "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
        "    subplot.imshow(mnist.test.images[i].reshape((28,28)), cmap=plt.gray())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxbduROUBdKY",
        "colab_type": "text"
      },
      "source": [
        "C:\\ProgramData\\Anaconda3\\envs\\LJH\\python.exe C:/Users/이종현/PycharmProjects/untitled3/data/MNIST7.py\n",
        "Extracting data/train-images-idx3-ubyte.gz\n",
        "Extracting data/train-labels-idx1-ubyte.gz\n",
        "Extracting data/t10k-images-idx3-ubyte.gz\n",
        "Extracting data/t10k-labels-idx1-ubyte.gz\n",
        "train dataset: (55000, 784) (55000, 10)\n",
        "test datset: (10000, 784) (55000, 10)\n",
        "validationi dataset: (5000, 784) (5000, 10)\n",
        "2020-06-03 01:29:14.953165: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
        "Epoch:  0001 Avg. Cost =  0.407\n",
        "Epoch:  0002 Avg. Cost =  0.151\n",
        "Epoch:  0003 Avg. Cost =  0.097\n",
        "Epoch:  0004 Avg. Cost =  0.071\n",
        "Epoch:  0005 Avg. Cost =  0.052\n",
        "Epoch:  0006 Avg. Cost =  0.040\n",
        "Epoch:  0007 Avg. Cost =  0.030\n",
        "Epoch:  0008 Avg. Cost =  0.025\n",
        "Epoch:  0009 Avg. Cost =  0.020\n",
        "Epoch:  0010 Avg. Cost =  0.018\n",
        "Epoch:  0011 Avg. Cost =  0.014\n",
        "Epoch:  0012 Avg. Cost =  0.015\n",
        "Epoch:  0013 Avg. Cost =  0.011\n",
        "Epoch:  0014 Avg. Cost =  0.012\n",
        "Epoch:  0015 Avg. Cost =  0.010\n",
        "Epoch:  0016 Avg. Cost =  0.007\n",
        "Epoch:  0017 Avg. Cost =  0.013\n",
        "Epoch:  0018 Avg. Cost =  0.008\n",
        "Epoch:  0019 Avg. Cost =  0.005\n",
        "Epoch:  0020 Avg. Cost =  0.011\n",
        "Optimized\n",
        "Accuracy:  0.323\n",
        "\n",
        "Process finished with exit code 0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWKx8JMbBesv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 3.1 위아래로 Flpping 한 MNIST dual layer perception code\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# read MNIST\n",
        "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
        "print('train dataset:',mnist.train.images.shape,mnist.train.labels.shape)\n",
        "print('test datset:',mnist.test.images.shape, mnist.train.labels.shape)\n",
        "print('validationi dataset:', mnist.validation.images.shape, mnist.validation.labels.shape)\n",
        "\n",
        "# placeholder to feed data to graph 28x28=784\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "# layer 1 processing\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L2, W3)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "# Data feed\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.InteractiveSession()\n",
        "# Pass image tensor object to a PIL image\n",
        "sess.run(init)\n",
        "\n",
        "# mini batch operation, batchsize=100\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "for epoch in range(20):\n",
        "    total_cost = 0\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        # flipping up<->down\n",
        "        batch_xs = np.flipud(batch_xs)\n",
        "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.8})\n",
        "        total_cost += cost_val\n",
        "\n",
        "    print('Epoch: ', '%04d' % (epoch + 1),'Avg. Cost = ', '{:.3f}'.format(total_cost / total_batch))\n",
        "print('Optimized')\n",
        "\n",
        "# Verification\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('Accuracy: ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
        "labels = sess.run(model, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1})\n",
        "\n",
        "\n",
        "# figure\n",
        "fig = plt.figure()\n",
        "for i in range(10):\n",
        "    subplot = fig.add_subplot(2, 5, i+1)\n",
        "    subplot.set_xticks([])\n",
        "    subplot.set_yticks([])\n",
        "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
        "    subplot.imshow(mnist.test.images[i].reshape((28,28)), cmap=plt.gray())\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6iTDYYbBzH-",
        "colab_type": "text"
      },
      "source": [
        "C:\\ProgramData\\Anaconda3\\envs\\LJH\\python.exe C:/Users/이종현/PycharmProjects/\n",
        "untitled3/data/MNIST7.py\n",
        "Extracting data/train-images-idx3-ubyte.gz\n",
        "Extracting data/train-labels-idx1-ubyte.gz\n",
        "Extracting data/t10k-images-idx3-ubyte.gz\n",
        "Extracting data/t10k-labels-idx1-ubyte.gz\n",
        "train dataset: (55000, 784) (55000, 10)\n",
        "test datset: (10000, 784) (55000, 10)\n",
        "validationi dataset: (5000, 784) (5000, 10)\n",
        "2020-06-03 01:51:31.038112: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
        "Epoch:  0001 Avg. Cost =  2.302\n",
        "Epoch:  0002 Avg. Cost =  2.302\n",
        "Epoch:  0003 Avg. Cost =  2.302\n",
        "Epoch:  0004 Avg. Cost =  2.302\n",
        "Epoch:  0005 Avg. Cost =  2.302\n",
        "Epoch:  0006 Avg. Cost =  2.302\n",
        "Epoch:  0007 Avg. Cost =  2.302\n",
        "Epoch:  0008 Avg. Cost =  2.302\n",
        "Epoch:  0009 Avg. Cost =  2.301\n",
        "Epoch:  0010 Avg. Cost =  2.302\n",
        "Epoch:  0011 Avg. Cost =  2.302\n",
        "Epoch:  0012 Avg. Cost =  2.302\n",
        "Epoch:  0013 Avg. Cost =  2.302\n",
        "Epoch:  0014 Avg. Cost =  2.302\n",
        "Epoch:  0015 Avg. Cost =  2.302\n",
        "Epoch:  0016 Avg. Cost =  2.301\n",
        "Epoch:  0017 Avg. Cost =  2.301\n",
        "Epoch:  0018 Avg. Cost =  2.301\n",
        "Epoch:  0019 Avg. Cost =  2.301\n",
        "Epoch:  0020 Avg. Cost =  2.301\n",
        "Optimized\n",
        "Accuracy:  0.1135"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K27BTisOB5JM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 4.1 90도 Rotation 한 dual layer perception code\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# read MNIST\n",
        "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
        "print('train dataset:',mnist.train.images.shape,mnist.train.labels.shape)\n",
        "print('test datset:',mnist.test.images.shape, mnist.train.labels.shape)\n",
        "print('validationi dataset:', mnist.validation.images.shape, mnist.validation.labels.shape)\n",
        "\n",
        "# placeholder to feed data to graph 28x28=784\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "# layer 1 processing\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L2, W3)\n",
        "\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
        "\n",
        "# Data feed\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.InteractiveSession()\n",
        "# Pass image tensor object to a PIL image\n",
        "sess.run(init)\n",
        "\n",
        "# mini batch operation, batchsize=100\n",
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)\n",
        "for epoch in range(20):\n",
        "    total_cost = 0\n",
        "    for i in range(total_batch):\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        # rotating 90 degrees\n",
        "        batch_xs = np.rot90(batch_xs).T\n",
        "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.8})\n",
        "        total_cost += cost_val\n",
        "\n",
        "    print('Epoch: ', '%04d' % (epoch + 1),'Avg. Cost = ', '{:.3f}'.format(total_cost / total_batch))\n",
        "print('Optimized')\n",
        "\n",
        "# Verification\n",
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('Accuracy: ', sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
        "labels = sess.run(model, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1})\n",
        "\n",
        "\n",
        "# figure\n",
        "fig = plt.figure()\n",
        "for i in range(10):\n",
        "    subplot = fig.add_subplot(2, 5, i+1)\n",
        "    subplot.set_xticks([])\n",
        "    subplot.set_yticks([])\n",
        "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
        "    subplot.imshow(mnist.test.images[i].reshape((28,28)), cmap=plt.gray())\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AE6fV23Cbxl",
        "colab_type": "text"
      },
      "source": [
        "C:\\ProgramData\\Anaconda3\\envs\\LJH\\python.exe C:/Users/이종현/PycharmProjects/untitled3/data/MNIST7.py\n",
        "Extracting data/train-images-idx3-ubyte.gz\n",
        "Extracting data/train-labels-idx1-ubyte.gz\n",
        "Extracting data/t10k-images-idx3-ubyte.gz\n",
        "Extracting data/t10k-labels-idx1-ubyte.gz\n",
        "train dataset: (55000, 784) (55000, 10)\n",
        "test datset: (10000, 784) (55000, 10)\n",
        "validationi dataset: (5000, 784) (5000, 10)\n",
        "2020-06-03 01:41:03.444854: I C:\\tf_jenkins\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\platform\\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
        "Epoch:  0001 Avg. Cost =  0.396\n",
        "Epoch:  0002 Avg. Cost =  0.148\n",
        "Epoch:  0003 Avg. Cost =  0.097\n",
        "Epoch:  0004 Avg. Cost =  0.069\n",
        "Epoch:  0005 Avg. Cost =  0.053\n",
        "Epoch:  0006 Avg. Cost =  0.040\n",
        "Epoch:  0007 Avg. Cost =  0.032\n",
        "Epoch:  0008 Avg. Cost =  0.024\n",
        "Epoch:  0009 Avg. Cost =  0.019\n",
        "Epoch:  0010 Avg. Cost =  0.017\n",
        "Epoch:  0011 Avg. Cost =  0.013\n",
        "Epoch:  0012 Avg. Cost =  0.014\n",
        "Epoch:  0013 Avg. Cost =  0.015\n",
        "Epoch:  0014 Avg. Cost =  0.007\n",
        "Epoch:  0015 Avg. Cost =  0.012\n",
        "Epoch:  0016 Avg. Cost =  0.010\n",
        "Epoch:  0017 Avg. Cost =  0.010\n",
        "Epoch:  0018 Avg. Cost =  0.008\n",
        "Epoch:  0019 Avg. Cost =  0.008\n",
        "Epoch:  0020 Avg. Cost =  0.006\n",
        "Optimized\n",
        "Accuracy:  0.3162\n",
        "\n",
        "Process finished with exit code 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goS8tRJOCfdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "https://github.com/BeefJerky0527/Homework.git"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}